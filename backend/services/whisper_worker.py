# backend/services/whisper_worker.py

"""
Whisper STT ì›Œì»¤

- ì…ë ¥ MQTT í† í”½
  1) interview/{user_id}/audio/pcm
     â†’ ë¸Œë¼ìš°ì € ì˜¤ë””ì˜¤ WebSocketì´ ë³´ë‚´ëŠ” Int16 PCM ì„ FastAPIê°€ ê·¸ëŒ€ë¡œ MQTTë¡œ í¼ë¸”ë¦¬ì‹œ

  2) interview/{user_id}/speech/segment
     â†’ speech_worker ê°€ ìŒì„± êµ¬ê°„ì„ ì¡ì•„ì„œ start_ts/end_ts/duration ì„ ë‹´ì•„ ì¨

- ì¶œë ¥ MQTT í† í”½
  3) interview/{user_id}/speech/text
     â†’ ì´ë²ˆ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•œ STT í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ë°œí–‰
"""

import json
import time
from typing import Dict, Any, List

import numpy as np
import paho.mqtt.client as mqtt
from faster_whisper import WhisperModel

# ==============================
# MQTT ê¸°ë³¸ ì„¤ì •
# ==============================
BROKER = "localhost"
PORT = 1883
KEEPALIVE = 60

CLIENT_ID = "whisper-worker"

# í† í”½ íŒ¨í„´
AUDIO_PCM_TOPIC = "interview/+/audio/pcm"
SEGMENT_TOPIC = "interview/+/speech/segment"

# ê²°ê³¼ í…ìŠ¤íŠ¸ë¥¼ í¼ë¸”ë¦¬ì‹œí•  í† í”½ í…œí”Œë¦¿
def speech_text_topic(user_id: str) -> str:
    return f"interview/{user_id}/speech/text"


# ==============================
# ì˜¤ë””ì˜¤ ë²„í¼ ê´€ë¦¬
# ==============================
# ì‚¬ìš©ìë³„ PCM ë²„í¼(ìµœê·¼ Nì´ˆë§Œ ìœ ì§€í•˜ëŠ” ì‹ìœ¼ë¡œ ê´€ë¦¬ ê°€ëŠ¥)
user_pcm_buffers: Dict[str, bytearray] = {}
# ì‚¬ìš©ìë³„ ë§ˆì§€ë§‰ ì˜¤ë””ì˜¤ ìˆ˜ì‹  ì‹œê°(ë””ë²„ê¹…ìš©)
user_last_audio_ts: Dict[str, float] = {}

# ìµœëŒ€ ë²„í¼ ê¸¸ì´(ìƒ˜í”Œ ê¸°ì¤€) â†’ ë„ˆë¬´ ê¸¸ì–´ì§€ì§€ ì•Šê²Œ ì˜ë¼ì¤„ ë•Œ ì‚¬ìš©
# (16kHz ê¸°ì¤€ 30ì´ˆ = 480000 ìƒ˜í”Œ â†’ 960000ë°”ì´íŠ¸)
SAMPLE_RATE = 16000
MAX_SAMPLES = SAMPLE_RATE * 30
SAMPLE_WIDTH = 2  # int16 = 2 bytes
MAX_BYTES = MAX_SAMPLES * SAMPLE_WIDTH

# ë…¸ì´ì¦ˆë¡œ ì¸í•œ í—›ì†Œë¦¬ ì „ì‚¬ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ìµœì†Œ RMS
MIN_AUDIO_RMS = 0.01

# ==============================
# Whisper ëª¨ë¸ ë¡œë“œ
# ==============================
print("[whisper_worker] Loading faster-whisper model (small, int8) ...")
model = WhisperModel(
    "small",
    device="cpu",
    compute_type="int8",
)
print("[whisper_worker] Model loaded.")


# ==============================
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# ==============================
def append_pcm(user_id: str, pcm_bytes: bytes) -> None:
    """ì‚¬ìš©ìë³„ë¡œ Int16 PCM ë°”ì´íŠ¸ë¥¼ ë²„í¼ì— ì¶”ê°€ (ë’¤ì— ìŒ“ê¸°)"""
    if not pcm_bytes:
        return

    # ê¸¸ì´ê°€ ì§ìˆ˜(=2ì˜ ë°°ìˆ˜)ê°€ ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ 1ë°”ì´íŠ¸ ì˜ë¼ëƒ„
    if len(pcm_bytes) % SAMPLE_WIDTH != 0:
        trimmed = len(pcm_bytes) - (len(pcm_bytes) % SAMPLE_WIDTH)
        pcm_bytes = pcm_bytes[:trimmed]

    buf = user_pcm_buffers.setdefault(user_id, bytearray())
    buf.extend(pcm_bytes)

    # ë„ˆë¬´ ì»¤ì§€ë©´ ë’¤ìª½ Në°”ì´íŠ¸ë§Œ ë‚¨ê¸°ê¸°
    if len(buf) > MAX_BYTES:
        # ë’¤ì—ì„œ MAX_BYTES ë§Œí¼ë§Œ ìœ ì§€
        user_pcm_buffers[user_id] = buf[-MAX_BYTES:]

    user_last_audio_ts[user_id] = time.time()


def trim_buffer(user_id: str, keep_sec: float = 1.0) -> None:
    """ì „ì‚¬ í›„ ì´ë¯¸ ì†Œë¹„í•œ êµ¬ê°„ì€ ë²„í¼ì—ì„œ ì œê±°í•´ ë°˜ë³µ ì „ì‚¬ë¥¼ ë§‰ìŒ."""
    buf = user_pcm_buffers.get(user_id)
    if not buf:
        return

    keep_samples = int(SAMPLE_RATE * max(0.0, keep_sec))
    keep_bytes = keep_samples * SAMPLE_WIDTH

    if keep_bytes <= 0:
        user_pcm_buffers[user_id] = bytearray()
    elif len(buf) > keep_bytes:
        user_pcm_buffers[user_id] = buf[-keep_bytes:]


def get_recent_pcm(user_id: str, max_duration_sec: float = 10.0) -> np.ndarray:
    """
    ìµœê·¼ max_duration_sec ì´ˆ ì •ë„ì˜ PCMì„ ì˜ë¼ì„œ ë°˜í™˜.
    - Int16 â†’ float32 [-1.0, 1.0] ë¡œ ë³€í™˜
    """
    buf = user_pcm_buffers.get(user_id)
    if not buf:
        return np.array([], dtype=np.float32)

    max_samples = int(SAMPLE_RATE * max_duration_sec)
    max_bytes = max_samples * SAMPLE_WIDTH

    if len(buf) > max_bytes:
        pcm_bytes = bytes(buf[-max_bytes:])
    else:
        pcm_bytes = bytes(buf)

    # ê¸¸ì´ ë°©ì–´: ì§ìˆ˜ byte ê°€ ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ 1ë°”ì´íŠ¸ ì˜ë¼ëƒ„
    if len(pcm_bytes) % SAMPLE_WIDTH != 0:
        trimmed = len(pcm_bytes) - (len(pcm_bytes) % SAMPLE_WIDTH)
        pcm_bytes = pcm_bytes[:trimmed]

    if len(pcm_bytes) == 0:
        return np.array([], dtype=np.float32)

    # Int16 â†’ float32 ë³€í™˜
    audio_int16 = np.frombuffer(pcm_bytes, dtype=np.int16)
    audio_float32 = audio_int16.astype(np.float32) / 32768.0

    return audio_float32


def rms(audio: np.ndarray) -> float:
    if audio.size == 0:
        return 0.0
    return float(np.sqrt(np.mean(np.square(audio))))


def transcribe_segment(user_id: str, segment_meta: Dict[str, Any]) -> None:
    """
    íŠ¹ì • user_id ì— ëŒ€í•´, í˜„ì¬ê¹Œì§€ ìŒ“ì¸ PCMì—ì„œ
    ìµœê·¼ Nì´ˆ(ì˜ˆ: 10ì´ˆ)ë¥¼ Whisperë¡œ ë³€í™˜í•˜ê³  ê²°ê³¼ë¥¼ MQTTë¡œ ë°œí–‰.
    """
    audio = get_recent_pcm(user_id, max_duration_sec=10.0)

    if audio.size == 0:
        print(f"[whisper_worker] [{user_id}] No PCM data available for STT.")
        return

    audio_rms = rms(audio)
    if audio_rms < MIN_AUDIO_RMS:
        # ì†ŒìŒì´ë‚˜ ì¡ìŒë§Œ ìˆëŠ” ê²½ìš° í”íˆ "êµ¬ë…ê³¼ ì¢‹ì•„ìš”" ê°™ì€ í—›ì†Œë¦¬ë¥¼ ìƒì„±í•˜ë¯€ë¡œ ê±´ë„ˆëœ€
        print(
            f"[whisper_worker] [{user_id}] Skip STT (low RMS={audio_rms:.4f}, likely noise)"
        )
        trim_buffer(user_id, keep_sec=0.5)
        return

    print(f"[whisper_worker] [{user_id}] Running Whisper on {len(audio)} samples...")

    # faster-whisper ëŠ” numpy array ë˜ëŠ” íŒŒí˜• íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ì„ ìˆ˜ ìˆìŒ
    # ì—¬ê¸°ì„œëŠ” numpy array ë¡œ ë°”ë¡œ ì…ë ¥
    segments, info = model.transcribe(
        audio,
        language="ko",    # í•œêµ­ì–´ ìœ„ì£¼ë¼ë©´ ëª…ì‹œ
        beam_size=5,
        vad_filter=True,
    )

    texts: List[str] = []
    for seg in segments:
        texts.append(seg.text)

    full_text = "".join(texts).strip()

    print(f"[whisper_worker] [{user_id}] STT TEXT: '{full_text}'")

    # speech_rate_worker ê°€ ì“°ê¸° ì¢‹ê²Œ ë©”íƒ€ë°ì´í„° í¬í•¨í•´ì„œ í¼ë¸”ë¦¬ì‹œ
    out_payload = {
        "user_id": user_id,
        "start_ts": segment_meta.get("start_ts"),
        "end_ts": segment_meta.get("end_ts"),
        "duration": segment_meta.get("duration"),
        "text": full_text,
    }

    topic = speech_text_topic(user_id)
    client: mqtt.Client = segment_meta["_client"]  # on_messageì—ì„œ ë„˜ê²¨ì¤Œ
    client.publish(topic, json.dumps(out_payload, ensure_ascii=False))
    # ì´ë¯¸ ì‚¬ìš©í•œ ì˜¤ë””ì˜¤ëŠ” ë²„í¼ì—ì„œ ì˜ë¼ ë°˜ë³µ ì „ì‚¬ë¥¼ ë°©ì§€
    trim_buffer(user_id, keep_sec=1.0)


# ==============================
# MQTT ì½œë°±
# ==============================
def on_connect(client, userdata, flags, reason_code, properties=None):
    print(f"[whisper_worker] Connected to MQTT broker: rc={reason_code}")
    client.subscribe(AUDIO_PCM_TOPIC)
    client.subscribe(SEGMENT_TOPIC)
    print(f"[whisper_worker] Subscribed to {AUDIO_PCM_TOPIC}")
    print(f"[whisper_worker] Subscribed to {SEGMENT_TOPIC}")


def on_message(client, userdata, msg):
    topic = msg.topic
    try:
        parts = topic.split("/")
        # interview / {user_id} / audio|speech / ...
        if len(parts) < 4:
            print("[whisper_worker] Unexpected topic:", topic)
            return

        _, user_id, category, subtopic, *rest = parts

        if category == "audio" and subtopic == "pcm":
            # ğŸ”¹ raw PCM ë°”ì´íŠ¸ ì²˜ë¦¬
            append_pcm(user_id, msg.payload)
            # ë””ë²„ê¹…ìš© (ì›í•˜ë©´ ì£¼ì„ í•´ì œ)
            # print(f"[whisper_worker] [{user_id}] Received PCM chunk: {len(msg.payload)} bytes")

        elif category == "speech" and subtopic == "segment":
            # ğŸ”¹ speech_workerê°€ ë³´ë‚´ì¤€ JSON ì„¸ê·¸ë¨¼íŠ¸ ë©”íƒ€ ì²˜ë¦¬
            payload_str = msg.payload.decode("utf-8")
            seg = json.loads(payload_str)

            start_ts = float(seg.get("start_ts", 0.0))
            end_ts = float(seg.get("end_ts", 0.0))
            duration = float(seg.get("duration", 0.0))

            print(
                f"[whisper_worker] [{user_id}] Segment event received "
                f"({start_ts:.2f} ~ {end_ts:.2f}, dur={duration:.2f}s)"
            )

            # segment_meta ì— client í•¸ë“¤ì„ ê°™ì´ ì „ë‹¬í•´ì„œ publish ì—ì„œ ì¬ì‚¬ìš©
            seg_meta = {
                "user_id": user_id,
                "start_ts": start_ts,
                "end_ts": end_ts,
                "duration": duration,
                "_client": client,
            }

            # âœ… ì—¬ê¸°ì—ì„œë§Œ STT ì‹¤í–‰
            transcribe_segment(user_id, seg_meta)

        else:
            print("[whisper_worker] Unknown category/subtopic:", category, subtopic)

    except Exception as e:
        print(f"[whisper_worker] on_message error on topic {topic}: {e}")


# ==============================
# main
# ==============================
def main():
    client = mqtt.Client(
        client_id=CLIENT_ID,
        callback_api_version=mqtt.CallbackAPIVersion.VERSION2,
    )
    client.on_connect = on_connect
    client.on_message = on_message

    client.connect(BROKER, PORT, KEEPALIVE)
    print("[whisper_worker] Started. Waiting for PCM + segments...")

    client.loop_forever()


if __name__ == "__main__":
    main()
